{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from ptr_decoder import pointer_decoder\n",
    "from pointer_network import PointerNetwork\n",
    "from data_generator import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "batch_size = 32\n",
    "seq_len = 8\n",
    "hidden_dim = 128\n",
    "lr = 0.01\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pointer_net = PointerNetwork(hidden_dim, lr, 10, sort, \n",
    "                             max_seq_len=seq_len, batch_size=batch_size, input_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Testing-------------------\n",
      "Epoch 0:\n",
      "Sample:\n",
      "ground truth: [ 0.04019927  0.06430691  0.22457752  0.56303015  0.64774744  0.70851185\n",
      "  0.79847057  0.85636531]\n",
      "prediction [ 0.22457752  0.22457752  0.22457752  0.22457752  0.22457752  0.22457752\n",
      "  0.22457752  0.22457752]\n",
      "Test loss is 18.1174\n",
      "Test accuracy is 0.0\n",
      "--------------------Done--------------------\n",
      "Epoch 0: training loss is 17.9078\n",
      "Epoch 50: training loss is 15.1607\n",
      "------------------Testing-------------------\n",
      "Epoch 100:\n",
      "Sample:\n",
      "ground truth: [ 0.5252165   0.59039069  0.73010986  0.7428869   0.7490249   0.78165124\n",
      "  0.82920861  0.97163153]\n",
      "prediction [ 0.5252165   0.5252165   0.5252165   0.7490249   0.97163153  0.97163153\n",
      "  0.97163153  0.97163153]\n",
      "Test loss is 11.4928\n",
      "Test accuracy is 0.0\n",
      "--------------------Done--------------------\n",
      "Epoch 100: training loss is 11.4639\n",
      "Epoch 150: training loss is 8.80549\n",
      "------------------Testing-------------------\n",
      "Epoch 200:\n",
      "Sample:\n",
      "ground truth: [ 0.12432993  0.21550984  0.38034912  0.47974136  0.51659704  0.66778498\n",
      "  0.71930784  0.94511883]\n",
      "prediction [ 0.12432993  0.21550984  0.38034912  0.47974136  0.51659704  0.71930784\n",
      "  0.94511883  0.94511883]\n",
      "Test loss is 6.60542\n",
      "Test accuracy is 0.09375\n",
      "--------------------Done--------------------\n",
      "Epoch 200: training loss is 7.54085\n",
      "Epoch 250: training loss is 6.29233\n",
      "------------------Testing-------------------\n",
      "Epoch 300:\n",
      "Sample:\n",
      "ground truth: [ 0.02985246  0.03215928  0.11181984  0.19064828  0.61259452  0.64942243\n",
      "  0.85768596  0.9794991 ]\n",
      "prediction [ 0.03215928  0.11181984  0.19064828  0.19064828  0.61259452  0.64942243\n",
      "  0.85768596  0.9794991 ]\n",
      "Test loss is 6.26479\n",
      "Test accuracy is 0.03125\n",
      "--------------------Done--------------------\n",
      "Epoch 300: training loss is 5.75189\n",
      "Epoch 350: training loss is 5.02776\n",
      "------------------Testing-------------------\n",
      "Epoch 400:\n",
      "Sample:\n",
      "ground truth: [ 0.23931182  0.31387605  0.39496683  0.53221106  0.59993233  0.73029956\n",
      "  0.86307996  0.92563292]\n",
      "prediction [ 0.23931182  0.31387605  0.39496683  0.53221106  0.59993233  0.73029956\n",
      "  0.86307996  0.92563292]\n",
      "Test loss is 4.83188\n",
      "Test accuracy is 0.34375\n",
      "--------------------Done--------------------\n",
      "Epoch 400: training loss is 5.34074\n",
      "Epoch 450: training loss is 4.16379\n",
      "------------------Testing-------------------\n",
      "Epoch 500:\n",
      "Sample:\n",
      "ground truth: [ 0.04618732  0.18462387  0.30175996  0.64852128  0.72186851  0.75608318\n",
      "  0.76628761  0.96153221]\n",
      "prediction [ 0.04618732  0.18462387  0.30175996  0.64852128  0.72186851  0.76628761\n",
      "  0.76628761  0.96153221]\n",
      "Test loss is 4.4041\n",
      "Test accuracy is 0.1875\n",
      "--------------------Done--------------------\n",
      "Epoch 500: training loss is 4.28906\n",
      "Epoch 550: training loss is 3.44791\n",
      "------------------Testing-------------------\n",
      "Epoch 600:\n",
      "Sample:\n",
      "ground truth: [ 0.00307024  0.00752883  0.34062228  0.42713022  0.46262464  0.48350235\n",
      "  0.52642741  0.61448306]\n",
      "prediction [ 0.00752883  0.00752883  0.34062228  0.34062228  0.42713022  0.48350235\n",
      "  0.52642741  0.61448306]\n",
      "Test loss is 4.21424\n",
      "Test accuracy is 0.21875\n",
      "--------------------Done--------------------\n",
      "Epoch 600: training loss is 4.1747\n",
      "Epoch 650: training loss is 3.63765\n",
      "------------------Testing-------------------\n",
      "Epoch 700:\n",
      "Sample:\n",
      "ground truth: [ 0.13067939  0.40641067  0.48769601  0.66477492  0.71642901  0.9004781\n",
      "  0.91836239  0.94968786]\n",
      "prediction [ 0.13067939  0.40641067  0.48769601  0.66477492  0.71642901  0.9004781\n",
      "  0.91836239  0.94968786]\n",
      "Test loss is 3.19204\n",
      "Test accuracy is 0.25\n",
      "--------------------Done--------------------\n",
      "Epoch 700: training loss is 2.6396\n",
      "Epoch 750: training loss is 3.16406\n",
      "------------------Testing-------------------\n",
      "Epoch 800:\n",
      "Sample:\n",
      "ground truth: [ 0.10322456  0.24316021  0.5361242   0.58432813  0.63814476  0.66488028\n",
      "  0.85134622  0.98785989]\n",
      "prediction [ 0.10322456  0.24316021  0.5361242   0.58432813  0.66488028  0.66488028\n",
      "  0.85134622  0.98785989]\n",
      "Test loss is 3.45686\n",
      "Test accuracy is 0.15625\n",
      "--------------------Done--------------------\n",
      "Epoch 800: training loss is 2.31591\n",
      "Epoch 850: training loss is 2.38567\n",
      "------------------Testing-------------------\n",
      "Epoch 900:\n",
      "Sample:\n",
      "ground truth: [ 0.07067808  0.25665364  0.48477536  0.50652108  0.65486429  0.76339736\n",
      "  0.8169276   0.87041996]\n",
      "prediction [ 0.07067808  0.25665364  0.48477536  0.50652108  0.65486429  0.76339736\n",
      "  0.87041996  0.87041996]\n",
      "Test loss is 2.41987\n",
      "Test accuracy is 0.40625\n",
      "--------------------Done--------------------\n",
      "Epoch 900: training loss is 1.93987\n",
      "Epoch 950: training loss is 2.95093\n",
      "------------------Testing-------------------\n",
      "Epoch 1000:\n",
      "Sample:\n",
      "ground truth: [ 0.074058    0.19169603  0.25052555  0.26044614  0.3658008   0.59852352\n",
      "  0.9726621   0.97734027]\n",
      "prediction [ 0.074058    0.19169603  0.25052555  0.3658008   0.3658008   0.59852352\n",
      "  0.9726621   0.97734027]\n",
      "Test loss is 2.90748\n",
      "Test accuracy is 0.25\n",
      "--------------------Done--------------------\n",
      "Epoch 1000: training loss is 3.19487\n",
      "Epoch 1050: training loss is 2.26778\n",
      "------------------Testing-------------------\n",
      "Epoch 1100:\n",
      "Sample:\n",
      "ground truth: [ 0.44763399  0.59031761  0.65557164  0.762891    0.79401043  0.8155174\n",
      "  0.84482912  0.89459245]\n",
      "prediction [ 0.44763399  0.59031761  0.65557164  0.762891    0.762891    0.8155174\n",
      "  0.89459245  0.89459245]\n",
      "Test loss is 1.92089\n",
      "Test accuracy is 0.5625\n",
      "--------------------Done--------------------\n",
      "Epoch 1100: training loss is 2.15762\n",
      "Epoch 1150: training loss is 1.69469\n",
      "------------------Testing-------------------\n",
      "Epoch 1200:\n",
      "Sample:\n",
      "ground truth: [ 0.34848609  0.39093113  0.39706334  0.63363976  0.87746474  0.94387249\n",
      "  0.97863239  0.99854559]\n",
      "prediction [ 0.34848609  0.39706334  0.39093113  0.63363976  0.87746474  0.87746474\n",
      "  0.94387249  0.97863239]\n",
      "Test loss is 2.68218\n",
      "Test accuracy is 0.46875\n",
      "--------------------Done--------------------\n",
      "Epoch 1200: training loss is 2.65566\n",
      "Epoch 1250: training loss is 1.90392\n",
      "------------------Testing-------------------\n",
      "Epoch 1300:\n",
      "Sample:\n",
      "ground truth: [ 0.00210386  0.05846282  0.09477262  0.10888165  0.13597039  0.38844859\n",
      "  0.63085783  0.96343959]\n",
      "prediction [ 0.00210386  0.00210386  0.05846282  0.09477262  0.13597039  0.38844859\n",
      "  0.63085783  0.96343959]\n",
      "Test loss is 2.25106\n",
      "Test accuracy is 0.4375\n",
      "--------------------Done--------------------\n",
      "Epoch 1300: training loss is 2.38263\n",
      "Epoch 1350: training loss is 2.34052\n",
      "------------------Testing-------------------\n",
      "Epoch 1400:\n",
      "Sample:\n",
      "ground truth: [ 0.08241021  0.17959013  0.34341376  0.34608378  0.47085876  0.57840095\n",
      "  0.86173989  0.93628652]\n",
      "prediction [ 0.08241021  0.17959013  0.34341376  0.34608378  0.47085876  0.57840095\n",
      "  0.86173989  0.93628652]\n",
      "Test loss is 3.32399\n",
      "Test accuracy is 0.40625\n",
      "--------------------Done--------------------\n",
      "Epoch 1400: training loss is 1.83711\n",
      "Epoch 1450: training loss is 1.70543\n",
      "------------------Testing-------------------\n",
      "Epoch 1500:\n",
      "Sample:\n",
      "ground truth: [ 0.09620824  0.47170133  0.72547591  0.72565385  0.72667741  0.8059542\n",
      "  0.81713142  0.97718225]\n",
      "prediction [ 0.09620824  0.47170133  0.72667741  0.72667741  0.72667741  0.8059542\n",
      "  0.81713142  0.97718225]\n",
      "Test loss is 1.91424\n",
      "Test accuracy is 0.625\n",
      "--------------------Done--------------------\n",
      "Epoch 1500: training loss is 1.76303\n",
      "Epoch 1550: training loss is 1.78339\n",
      "------------------Testing-------------------\n",
      "Epoch 1600:\n",
      "Sample:\n",
      "ground truth: [ 0.0237012   0.07853297  0.30932327  0.39385449  0.66880781  0.72260395\n",
      "  0.74186475  0.84707924]\n",
      "prediction [ 0.0237012   0.07853297  0.30932327  0.39385449  0.66880781  0.72260395\n",
      "  0.74186475  0.84707924]\n",
      "Test loss is 1.66859\n",
      "Test accuracy is 0.59375\n",
      "--------------------Done--------------------\n",
      "Epoch 1600: training loss is 1.469\n",
      "Epoch 1650: training loss is 2.07415\n",
      "------------------Testing-------------------\n",
      "Epoch 1700:\n",
      "Sample:\n",
      "ground truth: [ 0.06307587  0.09251676  0.30131659  0.40115563  0.56287925  0.72252077\n",
      "  0.81809182  0.90028482]\n",
      "prediction [ 0.06307587  0.09251676  0.30131659  0.40115563  0.56287925  0.72252077\n",
      "  0.81809182  0.90028482]\n",
      "Test loss is 1.54626\n",
      "Test accuracy is 0.625\n",
      "--------------------Done--------------------\n",
      "Epoch 1700: training loss is 1.60577\n",
      "Epoch 1750: training loss is 1.70181\n",
      "------------------Testing-------------------\n",
      "Epoch 1800:\n",
      "Sample:\n",
      "ground truth: [ 0.01062507  0.02074112  0.04523445  0.15292474  0.32667974  0.45778798\n",
      "  0.50015232  0.70076205]\n",
      "prediction [ 0.01062507  0.02074112  0.04523445  0.15292474  0.32667974  0.45778798\n",
      "  0.50015232  0.70076205]\n",
      "Test loss is 1.77737\n",
      "Test accuracy is 0.65625\n",
      "--------------------Done--------------------\n",
      "Epoch 1800: training loss is 2.13095\n",
      "Epoch 1850: training loss is 2.35287\n",
      "------------------Testing-------------------\n",
      "Epoch 1900:\n",
      "Sample:\n",
      "ground truth: [ 0.28309073  0.33211692  0.37154006  0.3819897   0.51118717  0.60558297\n",
      "  0.78050369  0.80558358]\n",
      "prediction [ 0.28309073  0.28309073  0.37154006  0.3819897   0.51118717  0.60558297\n",
      "  0.78050369  0.80558358]\n",
      "Test loss is 1.84338\n",
      "Test accuracy is 0.5625\n",
      "--------------------Done--------------------\n",
      "Epoch 1900: training loss is 1.554\n",
      "Epoch 1950: training loss is 1.13834\n",
      "------------------Testing-------------------\n",
      "Epoch 2000:\n",
      "Sample:\n",
      "ground truth: [ 0.05613875  0.21942879  0.22055014  0.44637923  0.56229705  0.72896221\n",
      "  0.73913735  0.95913961]\n",
      "prediction [ 0.05613875  0.05613875  0.21942879  0.44637923  0.56229705  0.72896221\n",
      "  0.73913735  0.95913961]\n",
      "Test loss is 1.60382\n",
      "Test accuracy is 0.53125\n",
      "--------------------Done--------------------\n",
      "Epoch 2000: training loss is 2.04853\n",
      "Epoch 2050: training loss is 2.20091\n",
      "------------------Testing-------------------\n",
      "Epoch 2100:\n",
      "Sample:\n",
      "ground truth: [ 0.11041979  0.312909    0.38088058  0.46433001  0.54526537  0.62285396\n",
      "  0.68706023  0.85295711]\n",
      "prediction [ 0.11041979  0.312909    0.38088058  0.46433001  0.54526537  0.62285396\n",
      "  0.68706023  0.85295711]\n",
      "Test loss is 1.37192\n",
      "Test accuracy is 0.5625\n",
      "--------------------Done--------------------\n",
      "Epoch 2100: training loss is 1.59845\n",
      "Epoch 2150: training loss is 1.57138\n",
      "------------------Testing-------------------\n",
      "Epoch 2200:\n",
      "Sample:\n",
      "ground truth: [ 0.04706004  0.29654544  0.41106338  0.44544932  0.51954388  0.62029918\n",
      "  0.84990911  0.94874784]\n",
      "prediction [ 0.04706004  0.29654544  0.41106338  0.44544932  0.51954388  0.62029918\n",
      "  0.84990911  0.94874784]\n",
      "Test loss is 1.90268\n",
      "Test accuracy is 0.65625\n",
      "--------------------Done--------------------\n",
      "Epoch 2200: training loss is 1.54328\n",
      "Epoch 2250: training loss is 1.1908\n",
      "------------------Testing-------------------\n",
      "Epoch 2300:\n",
      "Sample:\n",
      "ground truth: [ 0.03049705  0.23292226  0.24612362  0.29717664  0.34325806  0.48859949\n",
      "  0.57822704  0.91989027]\n",
      "prediction [ 0.03049705  0.23292226  0.24612362  0.29717664  0.34325806  0.48859949\n",
      "  0.57822704  0.91989027]\n",
      "Test loss is 1.76151\n",
      "Test accuracy is 0.59375\n",
      "--------------------Done--------------------\n",
      "Epoch 2300: training loss is 1.66509\n"
     ]
    }
   ],
   "source": [
    "pointer_net.train(sess, print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-9dd132341af6>:9 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "acc = pointer_net.acc\n",
    "predictions = pointer_net.predictions\n",
    "summary = pointer_net.summary\n",
    "opt = pointer_net.train_op\n",
    "loss = pointer_net.loss\n",
    "test_loss = pointer_net.test_loss\n",
    "decoder_outputs = pointer_net.decoder_outputs\n",
    "writer = pointer_net.writer\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 2 7 5 4 3 1 0]\n",
      "[7 7 7 7 7 7 7 7]\n",
      "0\n",
      "Loss 31.7577\n",
      "Test loss 97.4926\n",
      "acc 0.0\n",
      "[7 0 1 2 5 6 3 4]\n",
      "[7 7 5 6 6 6 4 4]\n",
      "0\n",
      "Loss 11.8414\n",
      "Test loss 10.6813\n",
      "acc 0.0\n",
      "[7 6 1 3 0 4 5 2]\n",
      "[7 6 1 1 3 0 2 2]\n",
      "0\n",
      "Loss 7.27988\n",
      "Test loss 7.60045\n",
      "acc 0.0\n",
      "[7 2 5 0 6 4 1 3]\n",
      "[7 2 5 0 6 4 3 3]\n",
      "2\n",
      "Loss 5.82286\n",
      "Test loss 6.07117\n",
      "acc 0.0625\n",
      "[5 6 2 3 1 0 7 4]\n",
      "[5 6 2 3 1 0 7 4]\n",
      "5\n",
      "Loss 5.11106\n",
      "Test loss 4.72052\n",
      "acc 0.15625\n",
      "[2 4 6 3 1 5 0 7]\n",
      "[2 4 4 6 1 0 0 7]\n",
      "4\n",
      "Loss 4.43266\n",
      "Test loss 5.04753\n",
      "acc 0.125\n",
      "[3 2 5 7 4 0 6 1]\n",
      "[3 2 5 7 4 0 6 1]\n",
      "9\n",
      "Loss 4.8902\n",
      "Test loss 4.6171\n",
      "acc 0.28125\n",
      "[2 0 1 6 3 5 4 7]\n",
      "[2 2 0 1 5 5 4 7]\n",
      "6\n",
      "Loss 3.33709\n",
      "Test loss 4.07957\n",
      "acc 0.1875\n",
      "[5 0 7 6 2 3 1 4]\n",
      "[5 0 7 6 2 3 1 4]\n",
      "14\n",
      "Loss 3.15501\n",
      "Test loss 3.32865\n",
      "acc 0.4375\n",
      "[2 0 6 4 5 3 1 7]\n",
      "[2 0 6 4 3 1 1 7]\n",
      "13\n",
      "Loss 3.13046\n",
      "Test loss 2.17995\n",
      "acc 0.40625\n",
      "[2 7 4 5 0 3 1 6]\n",
      "[2 7 5 5 0 3 1 6]\n",
      "19\n",
      "Loss 2.38906\n",
      "Test loss 2.11316\n",
      "acc 0.59375\n",
      "[2 6 0 3 1 5 7 4]\n",
      "[2 6 0 3 1 5 7 4]\n",
      "20\n",
      "Loss 2.57232\n",
      "Test loss 1.75355\n",
      "acc 0.625\n",
      "[2 7 6 0 1 3 4 5]\n",
      "[2 7 6 0 1 3 4 5]\n",
      "17\n",
      "Loss 2.36318\n",
      "Test loss 1.79901\n",
      "acc 0.53125\n",
      "[0 2 5 3 4 7 1 6]\n",
      "[0 2 5 3 4 4 1 6]\n",
      "15\n",
      "Loss 2.44832\n",
      "Test loss 2.60868\n",
      "acc 0.46875\n",
      "[4 7 6 0 5 1 3 2]\n",
      "[4 7 6 0 5 1 3 2]\n",
      "23\n",
      "Loss 1.42706\n",
      "Test loss 1.59575\n",
      "acc 0.71875\n",
      "[2 5 6 4 0 3 7 1]\n",
      "[2 5 6 4 0 3 7 1]\n",
      "14\n",
      "Loss 1.50766\n",
      "Test loss 1.87692\n",
      "acc 0.4375\n",
      "[7 4 1 0 2 6 5 3]\n",
      "[7 4 1 0 2 6 3 3]\n",
      "18\n",
      "Loss 2.3645\n",
      "Test loss 2.06739\n",
      "acc 0.5625\n",
      "[2 3 1 5 4 7 0 6]\n",
      "[2 3 1 5 4 7 7 6]\n",
      "13\n",
      "Loss 1.95056\n",
      "Test loss 1.95175\n",
      "acc 0.40625\n",
      "[0 4 1 3 2 7 6 5]\n",
      "[0 4 1 3 2 7 6 5]\n",
      "21\n",
      "Loss 1.37783\n",
      "Test loss 1.37745\n",
      "acc 0.65625\n",
      "[0 1 3 5 7 6 4 2]\n",
      "[0 1 5 5 7 6 4 2]\n",
      "24\n",
      "Loss 2.95318\n",
      "Test loss 1.13305\n",
      "acc 0.75\n",
      "[2 3 6 1 5 7 4 0]\n",
      "[2 3 6 1 5 7 4 0]\n",
      "25\n",
      "Loss 1.97386\n",
      "Test loss 1.08533\n",
      "acc 0.78125\n",
      "[1 0 5 2 3 6 4 7]\n",
      "[1 0 5 2 3 6 4 7]\n",
      "21\n",
      "Loss 1.66327\n",
      "Test loss 1.50548\n",
      "acc 0.65625\n",
      "[3 0 2 7 6 5 4 1]\n",
      "[3 0 2 7 6 5 4 1]\n",
      "18\n",
      "Loss 1.32673\n",
      "Test loss 1.75136\n",
      "acc 0.5625\n",
      "[1 5 4 7 6 3 2 0]\n",
      "[1 5 4 4 6 3 0 2]\n",
      "23\n",
      "Loss 1.91049\n",
      "Test loss 1.60772\n",
      "acc 0.71875\n",
      "[7 4 5 3 2 0 1 6]\n",
      "[7 4 5 3 2 0 1 6]\n",
      "12\n",
      "Loss 1.63773\n",
      "Test loss 2.49361\n",
      "acc 0.375\n",
      "[7 1 0 2 4 3 6 5]\n",
      "[7 1 0 2 4 3 6 5]\n",
      "11\n",
      "Loss 1.53419\n",
      "Test loss 2.52747\n",
      "acc 0.34375\n",
      "[1 2 4 7 0 6 3 5]\n",
      "[1 2 7 4 0 6 3 5]\n",
      "19\n",
      "Loss 1.30321\n",
      "Test loss 2.19779\n",
      "acc 0.59375\n",
      "[3 2 1 6 0 7 5 4]\n",
      "[3 2 1 6 7 0 5 4]\n",
      "22\n",
      "Loss 1.57106\n",
      "Test loss 1.33125\n",
      "acc 0.6875\n",
      "[4 6 7 5 2 3 0 1]\n",
      "[4 6 7 5 2 3 0 1]\n",
      "25\n",
      "Loss 1.03754\n",
      "Test loss 0.768543\n",
      "acc 0.78125\n",
      "[0 7 2 1 3 6 4 5]\n",
      "[0 7 2 1 3 6 6 5]\n",
      "19\n",
      "Loss 1.10648\n",
      "Test loss 1.08866\n",
      "acc 0.59375\n",
      "[1 3 5 4 7 0 6 2]\n",
      "[1 3 5 4 7 0 6 2]\n",
      "12\n",
      "Loss 1.47052\n",
      "Test loss 3.23073\n",
      "acc 0.375\n",
      "[7 6 0 1 3 5 2 4]\n",
      "[7 6 0 1 3 5 2 4]\n",
      "15\n",
      "Loss 1.06777\n",
      "Test loss 3.02589\n",
      "acc 0.46875\n",
      "[4 3 5 0 1 7 2 6]\n",
      "[4 3 5 0 1 7 2 6]\n",
      "21\n",
      "Loss 1.72723\n",
      "Test loss 1.69206\n",
      "acc 0.65625\n",
      "[3 1 4 0 2 7 6 5]\n",
      "[3 1 4 0 2 7 6 5]\n",
      "22\n",
      "Loss 1.68011\n",
      "Test loss 1.30664\n",
      "acc 0.6875\n",
      "[5 4 7 2 1 6 3 0]\n",
      "[5 4 7 2 1 6 3 0]\n",
      "23\n",
      "Loss 1.20863\n",
      "Test loss 1.17543\n",
      "acc 0.71875\n",
      "[1 4 6 7 0 3 2 5]\n",
      "[1 4 6 7 0 3 2 5]\n",
      "23\n",
      "Loss 1.07832\n",
      "Test loss 1.10301\n",
      "acc 0.71875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f5dae4c3d121>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                       encoder_inpt_data=_encoder_inps, target_data=_targets)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0m_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_vs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JunhongXu/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JunhongXu/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JunhongXu/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/JunhongXu/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JunhongXu/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# data = DataGenerator()\n",
    "for i in range(0, 100000):\n",
    "    _encoder_inps, _targets, _decoder_inps = sorting_generator(seq_len, batch_size)\n",
    "    feed_dict = pointer_net.feed_dict(decoder_inpt_data=_decoder_inps, \n",
    "                                      encoder_inpt_data=_encoder_inps, target_data=_targets)\n",
    "    \n",
    "    _loss, _, _vs, tr_s = sess.run([loss, opt, decoder_outputs, summary], feed_dict=feed_dict)\n",
    "    \n",
    "    writer.add_summary(tr_s, i)\n",
    "\n",
    "    if i%100 == 0:   \n",
    "        _encoder_inps, _targets, _decoder_inps = sorting_generator(seq_len, batch_size)\n",
    "        feed_dict = pointer_net.feed_dict(decoder_inpt_data=_decoder_inps, \n",
    "                                          encoder_inpt_data=_encoder_inps, target_data=_targets)\n",
    "        _test_loss, _acc, _pred, te_s = sess.run([test_loss, acc, predictions, summary], feed_dict=feed_dict)\n",
    "        writer.add_summary(te_s, i)\n",
    "        sample = np.random.randint(0, high=batch_size)\n",
    "        print np.argmax(np.array(_targets)[:, sample, :], axis=1)\n",
    "        print np.argmax(np.array(_pred)[:, sample, :], axis=1)\n",
    "        print np.sum(np.all(np.argmax(np.array(_pred), axis=2)==np.argmax(np.array(_targets), axis=2), \n",
    "                     axis=0))\n",
    "        print \"Loss\", _loss\n",
    "        print \"Test loss\", _test_loss\n",
    "        print \"acc\", _acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_encoder_inps, _targets, _decoder_inps = sorting_generator(8, 32, is_train=False)\n",
    "feed_dict = pointer_net.feed_dict(decoder_inpt_data=_decoder_inps, \n",
    "                                  encoder_inpt_data=_encoder_inps, target_data=_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_test_loss, _pred = sess.run([test_loss, pred], feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array(_pred).transpose(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 4, 5, 3, 7, 7, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(a[3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 4, 5, 3, 7, 2, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(_targets.transpose(1, 0, 2)[3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17182996],\n",
       "       [ 0.47429299],\n",
       "       [ 0.50111447],\n",
       "       [ 0.57148965],\n",
       "       [ 0.61954702],\n",
       "       [ 0.75696461],\n",
       "       [ 0.75696461],\n",
       "       [ 0.83725742]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_encoder_inps.transpose(1, 0, 2)[3][np.argmax(a[3], axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
